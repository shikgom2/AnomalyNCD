{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b59ff666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "keys: dict_keys(['model', 'optimizer', 'epoch', 'loss_list', 'base_category', 'category', 'mask_layers'])\n",
      "state_dict example keys: ['0.cls_token', '0.pos_embed', '0.patch_embed.proj.weight', '0.patch_embed.proj.bias', '0.blocks.0.norm1.weight', '0.blocks.0.norm1.bias', '0.blocks.0.attn.qkv.weight', '0.blocks.0.attn.qkv.bias', '0.blocks.0.attn.proj.weight', '0.blocks.0.attn.proj.bias', '0.blocks.0.norm2.weight', '0.blocks.0.norm2.bias', '0.blocks.0.mlp.fc1.weight', '0.blocks.0.mlp.fc1.bias', '0.blocks.0.mlp.fc2.weight', '0.blocks.0.mlp.fc2.bias', '0.blocks.1.norm1.weight', '0.blocks.1.norm1.bias', '0.blocks.1.attn.qkv.weight', '0.blocks.1.attn.qkv.bias']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "ckpt_path = \"../outputs/mvtec_cpr_crop/log/AnomalyNCD_capsule_(2025.12.15_09-21)/checkpoints/model.pt\"\n",
    "ckpt = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)\n",
    "\n",
    "print(type(ckpt))\n",
    "if isinstance(ckpt, dict):\n",
    "    print(\"keys:\", ckpt.keys())\n",
    "    sd = ckpt.get(\"state_dict\", ckpt.get(\"model\", ckpt))\n",
    "    print(\"state_dict example keys:\", list(sd.keys())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "857b66fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timm\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# model 생성/로드\n",
    "model = timm.create_model(\"vit_base_patch8_224\", pretrained=False, num_classes=0)\n",
    "missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "model = model.to(DEVICE).eval()\n",
    "print(\"model device:\", next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d64c0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMG_SIZE = 224\n",
    "GRID = 28\n",
    "tfm = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "def minmax(x, eps=1e-8):\n",
    "    x = x.astype(np.float32)\n",
    "    return (x - x.min()) / (x.max() - x.min() + eps)\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_patch_feats(pil_img):\n",
    "    x = tfm(pil_img).unsqueeze(0).to(DEVICE)         # [1,3,224,224]\n",
    "    feats = model.forward_features(x)                 # [1, 1+784, 768] (cls+patch)\n",
    "    if isinstance(feats, (tuple, list)):\n",
    "        feats = feats[0]\n",
    "    patch = feats[:, 1:, :]                           # [1,784,768]\n",
    "    patch = F.normalize(patch, dim=-1)\n",
    "    return patch.squeeze(0)                           # [784,768]\n",
    "\n",
    "@torch.no_grad()\n",
    "def build_bank(normal_dir, max_imgs=50):\n",
    "    bank = []\n",
    "    exts = (\".png\",\".jpg\",\".jpeg\",\".bmp\")\n",
    "    files = [f for f in sorted(os.listdir(normal_dir)) if f.lower().endswith(exts)]\n",
    "    files = files[:max_imgs]\n",
    "    for fn in files:\n",
    "        img = Image.open(os.path.join(normal_dir, fn)).convert(\"RGB\")\n",
    "        bank.append(extract_patch_feats(img))         # [784,768]\n",
    "    bank = torch.cat(bank, dim=0)                     # [max_imgs*784,768]\n",
    "    return bank\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_anomaly_map(pil_img, bank):\n",
    "    q = extract_patch_feats(pil_img)                  # [784,768]\n",
    "    # cosine similarity -> nearest neighbor distance\n",
    "    sim = q @ bank.t()                                # [784, M]\n",
    "    nn_sim, _ = sim.max(dim=1)                        # [784]\n",
    "    score = (1 - nn_sim).reshape(GRID, GRID)          # [28,28]\n",
    "    # upsample to 224x224\n",
    "    score = score.unsqueeze(0).unsqueeze(0)           # [1,1,28,28]\n",
    "    score_up = F.interpolate(score, size=(IMG_SIZE, IMG_SIZE), mode=\"bilinear\", align_corners=False)\n",
    "    return score_up.squeeze().cpu().numpy()           # [224,224]\n",
    "\n",
    "def save_evidence(pil_img, amap, out_png, percentile=95):\n",
    "    img = np.array(pil_img.resize((IMG_SIZE, IMG_SIZE)).convert(\"RGB\"))\n",
    "    hm = minmax(amap)\n",
    "\n",
    "    thr = float(np.percentile(hm, percentile))\n",
    "    mask = (hm >= thr).astype(np.uint8)\n",
    "\n",
    "    fig = plt.figure(figsize=(12,3))\n",
    "    gs = fig.add_gridspec(1,5, wspace=0.05)\n",
    "\n",
    "    ax = fig.add_subplot(gs[0,0]); ax.imshow(img); ax.set_title(\"Input\"); ax.axis(\"off\")\n",
    "    ax = fig.add_subplot(gs[0,1]); ax.imshow(hm, cmap=\"jet\"); ax.set_title(\"Anomaly Map\"); ax.axis(\"off\")\n",
    "    ax = fig.add_subplot(gs[0,2]); ax.imshow(img); ax.imshow(hm, cmap=\"jet\", alpha=0.45); ax.set_title(\"Overlay\"); ax.axis(\"off\")\n",
    "    ax = fig.add_subplot(gs[0,3]); ax.imshow(mask, cmap=\"gray\"); ax.set_title(f\"Binary (p{percentile})\"); ax.axis(\"off\")\n",
    "    ax = fig.add_subplot(gs[0,4]); ax.imshow(img); ax.imshow(mask, cmap=\"Reds\", alpha=0.35); ax.set_title(\"Mask Overlay\"); ax.axis(\"off\")\n",
    "\n",
    "    os.makedirs(os.path.dirname(out_png), exist_ok=True)\n",
    "    fig.savefig(out_png, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "'''\n",
    "\"../data/mvtec_cpr_crop/bottle/images/good\"\n",
    "\"../data/mvtec_cpr_crop/cable/images/good\"\n",
    "\"../data/mvtec_cpr_crop/capsule/images/good\"\n",
    "\"../data/mvtec_cpr_crop/carpet/images/good\"\n",
    "\"../data/mvtec_cpr_crop/grid/images/good\"\n",
    "\"../data/mvtec_cpr_crop/hazelnut/images/good\"\n",
    "'''\n",
    "normal_dir = \"../data/mvtec_cpr_crop/capsule/images/good\"\n",
    "test_img_path =\"../data/mvtec_cpr_crop/capsule/images/squeeze/000_crop0.png\"\n",
    "\n",
    "bank = build_bank(normal_dir, max_imgs=30)\n",
    "img = Image.open(test_img_path).convert(\"RGB\")\n",
    "amap = compute_anomaly_map(img, bank)\n",
    "\n",
    "save_evidence(img, amap, \"outputs/evidence/capsule.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
